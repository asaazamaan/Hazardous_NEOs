# **Predicting Hazardous NEOs (Near-Earth Objects)**  
A Machine Learning Project for Identifying Potentially Dangerous Asteroids  

---

## **Overview**
This project aims to predict whether a **Near-Earth Object (NEO)** is hazardous based on real-world data collected by **NASA (1910-2024)**. The dataset contains **338,199 records**, where each record represents an asteroid tracked for its proximity to Earth. Some objects are classified as *hazardous*, indicating potential risk to our planet.
---

## **Project Workflow**
 **Data Importing and cleaning** â†’**Exploratory Data Analysis (EDA)** â†’**Data Preprocessing** â†’**Model Training and Evaluation**

---

## **Features & Implementation**
### **1ï¸âƒ£ Data Cleaning & Preprocessing**
âœ”ï¸ **Handled missing values** by removing incomplete records  
âœ”ï¸ **Dropped unnecessary columns** (e.g., `neo_id`, `name`, `orbiting_body`)  
âœ”ï¸ **Removed duplicate rows**  
âœ”ï¸ **Checked class imbalance** (Found that hazardous asteroids are underrepresented)  
âœ”ï¸ **Feature Scaling** using `StandardScaler`  

### **2ï¸âƒ£ Exploratory Data Analysis (EDA)**
âœ”ï¸ **Visualized feature distributions** using histograms & pair plots  
âœ”ï¸ **Plotted correlations** between features using heatmaps  


### **3ï¸âƒ£ Feature Engineering**
âœ”ï¸ Created new features like:  
   - `size_ratio` â†’ ratio between max & min estimated diameter  
   - `velocity_size_ratio` â†’ relative velocity divided by max estimated diameter  
   - `inv_miss_distance` â†’ inverse of miss distance  
âœ”ï¸ **Removed less important features** based on feature importance analysis  

### **4ï¸âƒ£ Handling Imbalanced Classes**
âœ”ï¸ Used **SMOTE (Synthetic Minority Over-sampling Technique)** to balance the dataset  
âœ”ï¸ Ensured that SMOTE was applied **only on training data**  

### **5ï¸âƒ£ Model Training & Evaluation**
We trained and evaluated **five different models** using both **Stratified K-Fold Cross-Validation** and **Train-Test Split**:  

ğŸ“Œ **Models Used:**  
âœ”ï¸ **Logistic Regression**  
âœ”ï¸ **Decision Tree Classifier**  
âœ”ï¸ **Random Forest Classifier**  
âœ”ï¸ **XGBoost Classifier**  
âœ”ï¸ **CatBoost Classifier**  

ğŸ“Œ **Evaluation Metrics:**  
âœ”ï¸ **Accuracy**  
âœ”ï¸ **Precision**  
âœ”ï¸ **Recall**  
âœ”ï¸ **F1-Score**  
âœ”ï¸ **AUC-ROC Curve**  

---

## **Key Insights from Model Performance**
ğŸ“Œ **Best Model Selected:** **Random Forest Classifier**  
âœ”ï¸ **Achieved the highest AUC-ROC & F1-score**, making it the most reliable for detecting hazardous asteroids.  

âœ”ï¸ **Logistic Regression & Decision Tree struggled** with imbalanced data despite SMOTE.  
âœ”ï¸ **XGBoost & CatBoost performed well**, but **Random Forest outperformed them** in precision and recall balance.  

---

## **6ï¸âƒ£ Feature Importance Analysis**
âœ”ï¸ **Extracted feature importance from Random Forest**  
âœ”ï¸ **Visualized the most critical features** contributing to model predictions  

ğŸ“Œ **Top Features based on the best model (Random Forest):**  
1. **Estimated Diameter (Max)**   
2. **Absolute Magnitude**  
3. **magnitude_size_ratio**  
4. **velocity_size_ratio**  
5. **Relative Velocity**  

---

## **Technologies Used**
âœ”ï¸ Python  
âœ”ï¸ Pandas  
âœ”ï¸ NumPy  
âœ”ï¸ Matplotlib & Seaborn  
âœ”ï¸ Scikit-Learn  
âœ”ï¸ Imbalanced-learn (SMOTE)  
âœ”ï¸ XGBoost & CatBoost  

---

## **Installation & Usage**
### **Clone this repository**
```bash
git clone https:  https://github.com/asaazamaan/Hazardous_NEOs.git
cd Hazardous_NEOs
```

---

## **Acknowledgments**
âœ”ï¸ **Dataset sourced from [Kaggle: NASA NEO Dataset](https://www.kaggle.com/datasets/ivansher/nasa-nearest-earth-objects-1910-2024)**  
âœ”ï¸ **Developed as part of the MLSC Data Science & Machine Learning Course Graduation Project**  

---
